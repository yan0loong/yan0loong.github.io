<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Centos7搭建Hadoop集群</title>
      <link href="/2020/11/09/centos7-da-jian-hadoop-ji-qun/"/>
      <url>/2020/11/09/centos7-da-jian-hadoop-ji-qun/</url>
      
        <content type="html"><![CDATA[<h2 id="1-本文集群搭建分布及工具版本"><a href="#1-本文集群搭建分布及工具版本" class="headerlink" title="1. 本文集群搭建分布及工具版本"></a>1. 本文集群搭建分布及工具版本</h2><h3 id="1-工具及其版本"><a href="#1-工具及其版本" class="headerlink" title="1. 工具及其版本"></a>1. 工具及其版本</h3><pre><code>jdk1.8.0_231hadoop-2.7.7</code></pre><h3 id="2-集群部署规划"><a href="#2-集群部署规划" class="headerlink" title="2. 集群部署规划"></a>2. 集群部署规划</h3><table><thead><tr><th align="center"></th><th align="center">master</th><th align="center">slave1</th><th align="center">slave2</th></tr></thead><tbody><tr><td align="center">IP</td><td align="center">192.168.28.10</td><td align="center">192.168.28.11</td><td align="center">192.168.28.12</td></tr><tr><td align="center">内存</td><td align="center">4G</td><td align="center">4G</td><td align="center">4G</td></tr><tr><td align="center">HDFS</td><td align="center">NN/DN</td><td align="center">DN</td><td align="center">2NN/DN</td></tr><tr><td align="center">YARN</td><td align="center">NM</td><td align="center">RN/NM</td><td align="center">NM</td></tr></tbody></table><h2 id="2-安装三台虚拟机及基本配置"><a href="#2-安装三台虚拟机及基本配置" class="headerlink" title="2. 安装三台虚拟机及基本配置"></a>2. 安装三台虚拟机及基本配置</h2><h3 id="1-修改用户名以及对应IP"><a href="#1-修改用户名以及对应IP" class="headerlink" title="1. 修改用户名以及对应IP"></a>1. 修改用户名以及对应IP</h3><pre><code>配置主机名# vi /etc/hostname改为master另外那个虚拟机也按同样的设置，hostname文件内容分别改为 slave1、slave2。设置完后每台虚拟机都要重启，重启生效。配置完成后使用ping命令检查这3个机器是否相互ping得通，以slave1为例:# ping -c 3 slave1配置主机名映射# vi /etc/hosts配置如下：192.168.28.10 master192.168.28.11 slave1192.168.28.12 slave2</code></pre><h3 id="2-进行SSH免密互登设置"><a href="#2-进行SSH免密互登设置" class="headerlink" title="2. 进行SSH免密互登设置"></a>2. 进行SSH免密互登设置</h3><pre><code>在命令执行过程中敲击两遍回车，然后在/root/.ssh文件下生成id_dsa id_dsa.pub在该文件下建立一个authorized_keys文件，将id_dsa.pub文件内容拷贝到authorized_keys文件中另外两个虚拟机也进行相同的操作，并将自己的id_dsa.pub文件内容拷贝到其他两个虚拟机/root/.ssh下的authorized_keys文件中通过命令 # ssh slave1 看是否可以免密登录，可以通过exit退出</code></pre><h2 id="3-安装Java环境"><a href="#3-安装Java环境" class="headerlink" title="3. 安装Java环境"></a>3. 安装Java环境</h2><h3 id="1-解压jdk-8u231-linux-x64-tar-gz文件"><a href="#1-解压jdk-8u231-linux-x64-tar-gz文件" class="headerlink" title="1. 解压jdk-8u231-linux-x64.tar.gz文件"></a>1. 解压jdk-8u231-linux-x64.tar.gz文件</h3><pre><code>将下载的 jdk-8u231-linux-x64.tar.gz 的包上传到 master 环境的 /usr/local/src (我习惯讲所有东西放这个路径，可以自己建一个专门的文件夹来放这些包)路径下，然后 tar -xzvf jdk-8u231-linux-x64.tar.gz 解压到当前目录下，会生成一个 jdk1.8.0_231 文件夹</code></pre><h3 id="2-配置-jdk-环境变量"><a href="#2-配置-jdk-环境变量" class="headerlink" title="2. 配置 jdk 环境变量"></a>2. 配置 jdk 环境变量</h3><pre><code>修改 /etc/profile 这个文件，增加如下配置：export JAVA_HOME=/usr/local/src/jdk1.8.0_231export CLASSPATH=$:CLASSPATH:$JAVA_HOME/lib/export PATH=$PATH:$JAVA_HOME/bin修改后保存，然后再执行 source /etc/profile 命令使其生效然后执行 java -version 命令测试是否按照成功</code></pre><h2 id="3-安装Hadoop环境"><a href="#3-安装Hadoop环境" class="headerlink" title="3. 安装Hadoop环境"></a>3. 安装Hadoop环境</h2><h3 id="1-解压hadoop-2-7-7-tar-gz文件"><a href="#1-解压hadoop-2-7-7-tar-gz文件" class="headerlink" title="1. 解压hadoop-2.7.7.tar.gz文件"></a>1. 解压hadoop-2.7.7.tar.gz文件</h3><pre><code>将下载的 hadoop-2.7.7.tar.gz 的包上传到 master 环境的 /usr/local/src 路径下，然后 tar -xzvf hadoop-2.7.7.tar.gz 解压到当前目录下，会生成一个 hadoop-2.7.7 文件夹</code></pre><h3 id="2-配置hadoop环境变量"><a href="#2-配置hadoop环境变量" class="headerlink" title="2. 配置hadoop环境变量"></a>2. 配置hadoop环境变量</h3><pre><code>修改 /etc/profile 这个文件，增加如下配置：export HADOOP_HOME=/usr/local/src/hadoop-2.7.7修改 之前的 PATH 为如下：export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin修改后保存，然后再执行 source /etc/profile 命令使其生效然后执行 hadoop version 命令测试是否按照成功</code></pre><h3 id="3-核心配置文件"><a href="#3-核心配置文件" class="headerlink" title="3. 核心配置文件"></a>3. 核心配置文件</h3><h4 id="1-配置-masters-和-slaves-文件"><a href="#1-配置-masters-和-slaves-文件" class="headerlink" title="1. 配置 masters 和 slaves 文件"></a>1. 配置 masters 和 slaves 文件</h4><pre><code>如果没有这两个文件，自己创建就行。只需要将指定域名配置在这两个文件中，masters 文件中配置 master 节点的主机名，slaves 文件配置 slave 节点的主机名。masters 文件中添加:masterslaves 文件中添加:masterslave1slave2</code></pre><h4 id="2-核心配置文件"><a href="#2-核心配置文件" class="headerlink" title="2. 核心配置文件"></a>2. 核心配置文件</h4><pre><code>配置 core-site.xml在该文件下编辑如下配置：&lt;!-- 指定HDFS中NameNode的地址 --&gt;&lt;property&gt;    &lt;name&gt;fs.defaultFS&lt;/name&gt;    &lt;value&gt;hdfs://master:9000&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;&lt;property&gt;    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;    &lt;value&gt;/usr/local/src/hadoop-2.7.7/tmp&lt;/value&gt;&lt;/property&gt;</code></pre><h4 id="3-HDF配置文件"><a href="#3-HDF配置文件" class="headerlink" title="3. HDF配置文件"></a>3. HDF配置文件</h4><pre><code>配置 hadoop-env.sh添加java环境变量 export JAVA_HOME=/usr/local/src/jdk1.8.0_231配置 hdfs-site.xml在该文件中编写如下配置&lt;property&gt;    &lt;name&gt;dfs.replication&lt;/name&gt;    &lt;value&gt;3&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定Hadoop辅助名称节点主机配置 --&gt;&lt;property&gt;    &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;    &lt;value&gt;slave2:50090&lt;/value&gt;&lt;/property&gt;</code></pre><h4 id="4-YARN-置文件"><a href="#4-YARN-置文件" class="headerlink" title="4. YARN 置文件"></a>4. YARN 置文件</h4><pre><code>配置 yarn-env.sh添加java环境变量 export JAVA_HOME=/usr/local/src/jdk1.8.0_231配置 yarn-site.xml在该文件中增加如下配置&lt;!-- reducer获取数据的方式 --&gt;&lt;property&gt;    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定YARN的ResourceManager的地址 --&gt;&lt;property&gt;    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;    &lt;value&gt;slave1&lt;/value&gt;&lt;/property&gt;</code></pre><h4 id="5-MapReduce-配置文件"><a href="#5-MapReduce-配置文件" class="headerlink" title="5. MapReduce 配置文件"></a>5. MapReduce 配置文件</h4><pre><code>配置 mapred-env.sh添加java环境变量 export JAVA_HOME=/usr/local/src/jdk1.8.0_231配置 mapred-site.xml在该文件中增加如下配置&lt;!-- 指定mr运行在yarn上 --&gt;&lt;property&gt;    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;    &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;</code></pre><h2 id="4-分发配置文件"><a href="#4-分发配置文件" class="headerlink" title="4. 分发配置文件"></a>4. 分发配置文件</h2><h3 id="1-分发-etc-hosts-配置文件"><a href="#1-分发-etc-hosts-配置文件" class="headerlink" title="1. 分发 /etc/hosts 配置文件"></a>1. 分发 /etc/hosts 配置文件</h3><pre><code>将 master上的 /etc/hosts 文件分发到 slave1、slave2, 以下列子以 slave1 为列# scp -r /etc/hosts root@slave1:/etc/</code></pre><h3 id="2-分发-etc-profile-配置文件"><a href="#2-分发-etc-profile-配置文件" class="headerlink" title="2. 分发 /etc/profile 配置文件"></a>2. 分发 /etc/profile 配置文件</h3><pre><code>将 master上的 /etc/profile 文件分发到 slave1、slave2, 以下列子以 slave1 为列# scp -r /etc/profile root@slave1:/etc/分发后分别在三台虚拟机上执行 source /etc/profile 使其配置生效</code></pre><h3 id="3-分发-java-文件"><a href="#3-分发-java-文件" class="headerlink" title="3. 分发 java 文件"></a>3. 分发 java 文件</h3><pre><code>将 master上的 /usr/local/src/jdk1.8.0_231 文件分发到 slave1、slave2, 以下列子以 slave1 为列# scp -r /usr/local/src/jdk1.8.0_231 root@slave1:/usr/local/src/</code></pre><h3 id="4-分发-hadoop-文件"><a href="#4-分发-hadoop-文件" class="headerlink" title="4. 分发 hadoop 文件"></a>4. 分发 hadoop 文件</h3><pre><code>将 master上的 /usr/local/src/hadoop-2.7.7 文件分发到 slave1、slave2, 以下列子以 slave1 为列# scp -r /usr/local/src//usr/local/src/hadoop-2.7.7 root@slave1:/usr/local/src/</code></pre><h2 id="5-启动集群"><a href="#5-启动集群" class="headerlink" title="5. 启动集群"></a>5. 启动集群</h2><pre><code>如果集群是第一次启动，需要格式化 NameNode# bin/hdfs namenode -format启动集群# sbin/start-all.sh</code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/04/21/hello-world/"/>
      <url>/2020/04/21/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class=" language-bash"><code class="language-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class=" language-bash"><code class="language-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class=" language-bash"><code class="language-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
